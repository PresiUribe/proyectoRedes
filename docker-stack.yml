version: "3.8"

services:
  kafka:
    image: bitnami/kafka:latest
    environment:
      # arranca en modo KRaft: broker + controller
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      # identificador único de este nodo
      - KAFKA_CFG_NODE_ID=1
      # voters para el quorum de controller (ID@host:port)
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      # listeners internos
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      # cómo se ve desde fuera
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    ports:
      - "9092:9092"
      - "9093:9093"    # para el controller
    networks:
      back:
        aliases:
          - kafka


  ## 3) Base de datos MySQL
  db:
    image: mysql:8.0
    container_name: db
    environment:
      - MYSQL_ROOT_PASSWORD=mysql
    volumes:
      - db_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - ./Airbnb_Texas_Rentals.csv:/var/lib/mysql-files/propiedades.csv:ro
    networks:
      - back

  ## 4) Microservicios (usuario, reservas, propiedades, pagos) …
  usuario_ms:
    image: usuario_ms:latest
    depends_on: [db]
    environment:
      - DB_HOST=db
      - DB_USER=root
      - DB_PASSWORD=mysql
      - DB_NAME=usuariosMS
    deploy:
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    networks:
      - back

  reservas_ms:
    image: reservas_ms:latest
    depends_on: [db]
    environment:
      - DB_HOST=db
      - DB_USER=root
      - DB_PASSWORD=mysql
      - DB_NAME=reservasMS
    deploy:
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    networks:
      - back

  propiedades_ms:
    image: propiedades_ms:latest
    depends_on: [db]
    environment:
      - DB_HOST=db
      - DB_USER=root
      - DB_PASSWORD=mysql
      - DB_NAME=propiedadesMS
    deploy:
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    networks:
      - back

  pagos_ms:
    image: pagos_ms:latest
    depends_on: [db]
    environment:
      - DB_HOST=db
      - DB_USER=root
      - DB_PASSWORD=mysql
      - DB_NAME=pagosMS
    deploy:
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    networks:
      - back

  ## 5) HAProxy + exporter
  haproxy:
    image: haproxy:2.6-alpine
    depends_on:
      - usuario_ms
      - reservas_ms
      - propiedades_ms
      - pagos_ms
    ports:
      - "80:80"
      - "8404:8404"
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 5s
      restart_policy:
        condition: on-failure
    networks:
      - back

  haproxy-exporter:
    image: prom/haproxy-exporter:latest
    command:
      - --haproxy.scrape-uri=http://admin:secret@haproxy:8404/stats;csv
    ports:
      - "9101:9101"
    networks:
      - back

  ## 6) Prometheus (lee prometheus.yml)
  prometheus:
    image: prom/prometheus:latest
    depends_on:
      - haproxy
      - spark-master
      - spark-worker
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    networks:
      - back

  ## 7) Grafana apuntando a prometheus
  grafana:
    image: grafana/grafana:latest
    container_name: proyecto_grafana
    depends_on:
      - prometheus
    ports:
      - "3003:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:%(http_port)s
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    networks:
      - back

  ## 8) Frontend estático
  frontend:
    image: nginx:alpine
    volumes:
      - ./front:/usr/share/nginx/html:ro
      - ./front/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "8080:80"
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
    networks:
      - back

  ## 9) Spark Master
  spark-master:
    image: bitnami/spark:3.3.2
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=0.0.0.0      # <-- bind a todas las interfaces
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    networks:
      - back

  spark-worker:
    image: bitnami/spark:3.3.2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - back

  spark-job:
    image: bitnami/spark:3.3.2
    depends_on:
      - spark-master
      - spark-worker
    environment:
      - SPARK_MODE=submit
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark/streaming_job.py:/opt/app/streaming_job.py:ro
    command: >
      bash -lc "exec /opt/bitnami/spark/bin/spark-submit \
        --master $SPARK_MASTER_URL \
        /opt/app/streaming_job.py"
    networks:
      - back


networks:
  back:
    driver: overlay

volumes:
  db_data:
